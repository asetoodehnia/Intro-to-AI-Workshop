{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup\n",
    "\n",
    "First we need to lay out the problem we're working through. This consists of defining the possible states and actions, and optionally the actions that are legal at each state. In order to perform value iteration we'll also need the transition probabilities and rewards when moving from state to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [\"cold\", \"warm\", \"overheated\"]\n",
    "actions = [\"slow\", \"fast\"]\n",
    "Legal_Actions = {\"cold\": [\"slow\",\"fast\"],\n",
    "                 \"warm\": [\"slow\",\"fast\"],\n",
    "                 \"overheated\": []\n",
    "                }\n",
    "\n",
    "transitions = {(\"cold\", \"slow\", \"cold\"): 1,\n",
    "               (\"cold\", \"fast\", \"cold\"): .5,\n",
    "               (\"cold\", \"slow\", \"warm\"): 0,\n",
    "               (\"cold\", \"fast\", \"warm\"): .5,\n",
    "               (\"cold\", \"slow\", \"overheated\"): 0,\n",
    "               (\"cold\", \"fast\", \"overheated\"): 0,\n",
    "               \n",
    "               (\"warm\", \"slow\", \"cold\"): .5,\n",
    "               (\"warm\", \"fast\", \"cold\"): 0,\n",
    "               (\"warm\", \"slow\", \"warm\"): .5,\n",
    "               (\"warm\", \"fast\", \"warm\"): 0,\n",
    "               (\"warm\", \"slow\", \"overheated\"): 0,\n",
    "               (\"warm\", \"fast\", \"overheated\"): 1,\n",
    "              }\n",
    "\n",
    "rewards = {(\"cold\", \"slow\"): 1,\n",
    "           (\"cold\", \"fast\"): 2,\n",
    "           \n",
    "           (\"warm\", \"slow\"): 1,\n",
    "           (\"warm\", \"fast\"): -10,\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value, Q, and Policy iteration\n",
    "\n",
    "Implement a simple function for each type of iteration (hint: they should be very similar)\n",
    "\n",
    "For reference, here is a copy of the Bellman Equation\n",
    "$$\\Large\n",
    "Q^*(s,a) =\\sum_{s'} T(s,a,s')[R(s,a,s') + \\gamma V^* (s')]\n",
    "$$\n",
    "\n",
    "Feel free to define any helper functions you want or keep everything in the same block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_iteration(states, actions, Legal_Actions, T, R, gamma, max_iter=100):\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize all entries in v to 0\n",
    "    for state in states:\n",
    "        v[state] = 0\n",
    "        \n",
    "    # Iterate until max_iter is reached\n",
    "    for i in range(max_iter):\n",
    "        for s in states:\n",
    "            # Calculate the value of the maximum legal action, this is in a try-catch because there may be no legal actions\n",
    "            # which would cause max([]) to throw a value error\n",
    "            try:\n",
    "                v[s] = max([sum([T[(s,a,s_prime)] * (R[(s,a)] + gamma * v[s_prime]) for s_prime in states]) for a in Legal_Actions[s]])\n",
    "            except:\n",
    "                v[s]=0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_iteration(states, actions, Legal_Actions, T, R, gamma, max_iter=100):\n",
    "    q={}\n",
    "    v={}\n",
    "    \n",
    "    # Initialize all legal entries in q and v to 0\n",
    "    for state in states:\n",
    "        v[state] = 0\n",
    "        for action in Legal_Actions[state]:\n",
    "            q[(state,action)] = 0\n",
    "\n",
    "    # Iterate until max_iter is reached        \n",
    "    for i in range(max_iter):\n",
    "        for s in states:\n",
    "            for a in Legal_Actions[s]:\n",
    "                # For each legal s,a pair evaluate Q(s,a)\n",
    "                q[(s,a)] = sum([T[(s,a,s_prime)] * (R[(s,a)] + gamma * v[s_prime]) for s_prime in states])\n",
    "            \n",
    "            # Place the maximum result into v[s], this is in a try-catch because there may be no legal actions\n",
    "            # which would cause max([]) to throw a value error\n",
    "            try:\n",
    "                v[s] = max([q[(s,a)] for a in Legal_Actions[s]])\n",
    "            except:\n",
    "                v[s]=0\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, Legal_Actions, T, R, gamma, max_iter=10):\n",
    "    pi = {}\n",
    "    q = {}\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize all legal entries in pi, q, and v to 0 or a random value as appropriate\n",
    "    for state in states:\n",
    "        v[state] = 0\n",
    "        try:\n",
    "            pi[state] = random.choice(Legal_Actions[state])\n",
    "        except:\n",
    "            pass\n",
    "        for action in Legal_Actions[state]:\n",
    "            q[(state, action)] = 0\n",
    "            \n",
    "    # Iterate until max_iter is reached\n",
    "    for i in range(max_iter):\n",
    "        for s in states:\n",
    "            for a in Legal_Actions[s]:\n",
    "                # For each legal s,a pair evaluate Q(s,a)\n",
    "                q[(s,a)] = sum([T[(s,a,s_prime)] * (R[(s,a)] + gamma * v[s_prime]) for s_prime in states])\n",
    "           \n",
    "            # Place the maximum result into v[s], this is in a try-catch because there may be no legal actions\n",
    "            # which would cause max([]) to throw a value error\n",
    "            try:\n",
    "                pi[s] = Legal_Actions[s][np.argmax([q[(s,a)] for a in Legal_Actions[s]])]\n",
    "                v[s] = q[(s, pi[s])]\n",
    "            except:\n",
    "                v[s]=0\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = value_iteration(states, actions, Legal_Actions, transitions, rewards, 0.9)\n",
    "q_values = q_iteration(states, actions, Legal_Actions, transitions, rewards, 0.9)\n",
    "learned_policy = policy_iteration(states, actions, Legal_Actions, transitions, rewards, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert learned_policy[\"cold\"] == \"fast\", \"The policy chose the wrong action when the engine is cold\"\n",
    "assert learned_policy[\"warm\"] == \"slow\", \"The policy chose the wrong action when the engine is warm\"\n",
    "assert state_values[\"cold\"] == max([q_values[(\"cold\",a)] for a in Legal_Actions[\"cold\"]]), \"Value iteration did not choose the maximizing action\"\n",
    "assert np.isclose(state_values[\"cold\"], 15.5), \"Value iteration converged to the wrong value\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
